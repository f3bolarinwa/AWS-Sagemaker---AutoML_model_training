# Project: Predict Bike Sharing Demand

A program requirement for AWS Machine Learning Engineer Nanodegree @ Udacity School of Artificial Intelligence

Dataset available through kaggle competition here: 
https://www.kaggle.com/c/bike-sharing-demand/overview

## Project Description on Kaggle

Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.

## My Work Description

In this project, I used the AWS AutoML frameowrk (AutoGluon library) to train several models for the Bike Sharing Demand. I used AutoGluon Tabular Prediction to fit data from CSV files provided by the competition. I used the AutoML framework to train several iterations of models and conduct hyper-parameter optimization to achieve better model performance against unseen test data. 

The project was completed live on AWS cloud platform using Amazon Sagemaker studio

## AWS Sagemaker Studio SetUp

Instance: ml.t3.medium instance (2 vCPU + 4 GiB)

Kernel: Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)

Sagemaker Image: Data Science 3.0

## Repository Content Description

1)bike-sharing-demand.zip: bike sharing demand dataset in zip folder

2)train.csv: train dataset

3)test.csv: test dataset

4)sampleSubmission.csv: submission dataframe format required by kaggle

5)Solution Notebook.ipynb: solution jupyter notebook completed on AWS sagemaker

6)submission report.md: submission report

7)submission.csv: initial test data predictions submission with default predictor columns

8)submission_new_features.csv: tests data predictions submission with new featured engineered

9)submission_new_hpo.csv: test data predictions submission with optimized hyper-parameters

10)kaggle/kaggle.json: contains my personal kaggle API token

11)images: contains sanpshot model performance trends and AWS sagemaker studio

